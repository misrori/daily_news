[
    {
        "video_id": "_I3j6n0vBc0",
        "title": "Nvidia According to Dan Ives",
        "published_at": "2025-12-15T15:01:11.000Z",
        "sort_date": "2025-12-15",
        "url": "https://www.youtube.com/watch?v=_I3j6n0vBc0",
        "views": 3908,
        "duration": "00:07:17",
        "transcript": "The Dan I just pulled the curtain on Google's recent AI attention and oh my god he wasn't holding back. According to him the frenzy is blinding everyone to what's actually happening behind the scenes. Google's Gemini 3 took the internet by storm beating every other model in the market on each benchmark from coding and math all the way to reasoning. It practically sent every competitor into panic mode with open AI even announcing a code red. Safe to say Google wiped the competition hard and clean. With the model success, people started believing that Google was the way to go. Coupled with Google's TPU chips, a direct competitor to Nvidia's GPUs, you were looking at a complete AI ecosystem by Google that was outdoing its competitors by a landslide. Everyone was convinced that they should just close their eyes and put their money into Google and wait for it to rain. Well, Dan I says not so fast. While Google might be gaining unreal hype at the moment, he claims that Nvidia is still the indisputable Rocky Balboa of the AI revolution and that it's not changing anytime soon. While Google might be ruling the generative AI space right now, according to Dan Ies, it's a completely different ballgame when it comes to chips, and the competition isn't even close. Nvidia powers roughly a whopping 90% of the data center market. Simply put, Nvidia is the powerhouse behind most of the AI in the world right now, and the demand for Google's TPUs isn't nearly as impressive. In an interview with Bloomberg, Dan said that there is one godfather of AI, and that's Jensen. Not only has Nvidia captured the bulk of the market share in the AI hardware space, but it continues to innovate, improving the value its chips provide. And if there's one thing that big players like OpenAI and Anthropic know, it's that they can always rely on Nvidia. For any company using AI for its core service, innovation is everything. A new feature here, a slight accuracy bump there, and you're already outperforming everyone else in the market. That sort of innovation requires reliable hardware, and Nvidia certainly has that front covered. That's one of the reasons that GPUs are so popular, or in Dan's words, it continues to be Nvidia's world, and everyone else is just paying rent. Nvidia is far ahead of anyone just starting out in making their own chips. And it doesn't matter if it's trillion dollar companies like Google or Amazon. It's a lot of trial and error and no one gets it right on the first or even their second try. Luckily for Nvidia, they've paid their dues years in advance. Even if Google does catch up on the tech, it's more likely to keep playing catch-up with Nvidia because Jensen will be cooking up the next big thing in the meantime. Don't get me wrong, Google's TPUs are great and they're getting better by the day, but as things stand at the moment, Nvidia is just better. According to Dan, when compared to every other chip on the market, Nvidia's at least four years ahead and at the pace things move in AI, that is a hell of a lot. However, that also says that the demand to supply ratio for AI chips right now is 12:1. So, Nvidia certainly isn't able to keep up with all that demand in the market. That means more room for Google to establish itself. But here's the flip side, and one that could prove to be dangerous for Google. Since Google can't capture a significant share of the market right now, with the market more ripe than it ever has been, it will only become harder for Google once Nvidia scales its supply. Even with all the excess demand for AI compute and the server supply shortage on Nvidia's end at the moment, not a lot of companies have switched over to Google's TPUs. The baseline is that people want to make the switch. They want to incorporate AI wherever they can, but right now, Nvidia is what they're betting on to make that happen. But this reveals something much more interesting about where the AI market is headed. That 12:1 demand to supply ratio means there's 3 to 4 trillion yet to be spent on AI compute alone in the next few years. Combine that with what these enterprises are expecting consumers to spend on in the next few years, and you've easily topped the $10 trillion mark. Even if those exact estimates are optimistic, one thing is clear. Dan Ies thinks AI is not a bubble and it's only going onward and upward from here. No matter what the critics say and no matter how many comparisons you make with the dotcom bubble, AI is here to stay for good. The only people who are missing out are the ones waiting for it to collapse. So when we rack up years worth of demand for AI chips, trillions of dollars of investments, and possibly even more consumer spend, we're all looking at one thing, and it's that AI revolution. The reality is it's all being built on top of one chip at the moment, and that's Nvidia's. So when a multi-trillion dollar industry is being built almost exclusively through your hardware, it's hard not to put your chips into Nvidia. They have the market share, they have the tech, and the demand is about to go through the roof. So, what does this mean for Nvidia's stock? According to Dan, their recent growth was just the beginning, and the next leg of Nvidia's growth story has only just begun. So, if you thought that Nvidia's $5 trillion market cap in 2025 was groundbreaking news, you're in for a treat because it's only going to get bigger and better from here, according to Dan. But this isn't bad news for Google either. It's progressing fast and its AI integration across the ecosystem is honestly the most seamless we've seen so far. Given Microsoft's copilot and the mess Apple intelligence is turning out to be, Google is leading the AI ecosystem and Gemini 3 is giving generative AI pioneers like Open AI and Anthropic a run for their money. Safe to say Google has come a long way from Bard. So why can't all this tech translate to numbers like Nvidia's? Because when you're competing with Nvidia, you're officially playing with the big boys. As Dan I puts it, Nvidia isn't just assisting the AI revolution at this point. It's powering it. Almost every AI chatbot you use is trained using Nvidia's GPUs. Almost every AI generated photo you see was most likely processed using Nvidia hardware. Every video, yes, you guessed it. So, while Google might be progressing at a faster rate than ever, the gap in the chip market with Nvidia still exists. Moreover, the tech market trends according to Dan are only going to further increase this gap. With every business looking to develop its own proprietary AI, train its own models, and basically make its own version of GPT trained on its own data, the demand is about to shift big time. This would mean a shift in demand from a few big names to almost every other company that could justify an AI use case. That's just all the more demand for Nvidia because it still has an approximate 90% market share in the AI hardware space. Dan believes that big tech is expected to remain the dominant force in financial markets as investors continue to pour billions into companies that are driving the next phase of artificial intelligence. So, every time a company finds a slightly different use case for AI or builds something new on top of existing technology, expect that to be a tailwind for big tech stocks."
    },
    {
        "video_id": "ZoqktC0sQPs",
        "title": "Palmer Luckey Takes the Gloves Off",
        "published_at": "2025-12-15T12:01:18.000Z",
        "sort_date": "2025-12-15",
        "url": "https://www.youtube.com/watch?v=ZoqktC0sQPs",
        "views": 7169,
        "duration": "00:08:54",
        "transcript": "And rule CEO Palmer Lucky just let rip on some jaw-dropping takes. You know, it's always going to be an entertaining one when Palmer turns up. Enjoy. >> Shows last week about AI and the use in military and battle and how it's changing everything. But there are a lot of concerns from people about the use of that technology where humans are sort of taken out of a lot of interaction with decisions that can lead to taking lives and serious life and death situations. How do we manage that? Well, I like to like to point out I've been thinking about these problems for a lot longer than most of those critics. I mean, when I started Androll, I eight, you know, eight and a half almost nine years ago, most people thought AI was this crazy sci-fi thing that was always going to be in the future, never quite in the present. You the present. They they thought it almost like, you know, time travel or uh or uh you know, uh or virtual reality even. Uh but Anderal Industries, you might notice the acronym is AI for a reason. I believed that AI was not just going to come eventually but imminently and that we were going to be able to apply it to these national security problems. When it comes to life and death decisionm I think that is too morally fraugh an area. It is too critical of an area to not apply the best technology available to you. Regardless of what it is, whether it's a AI or or quantum or anything else, if you're talking about killing people, you need to be minimizing the amount of collateral damage. You need to be as certain as you can in anything that you do need. You need to be as effective as possible. And so to me, there's no moral high ground in using inferior technology, even if it allows you to say things like, \"We never let a robot decide who lives and who dies.\" Where's the moral high ground in, for example, an anti-vehicle landmine that can't tell the difference between a school bus full of kids and a column of Russian armor? Is that really making you a better person because you've made your smart weapon into a dumb weapon? Same thing for a missile that can't differentiate between, let's say, a civilian boat and a military vessel. Is there really a moral high ground and saying, \"Well, at least the AI didn't make the decision as to which boat to strike.\" Again, I think that for these problem, these matters of life and death, it's too critical a problem to not apply the best technology. Sometimes that will be AI, sometimes it won't be AI, but it's really about using the best tech to make sure that you're treating these problems as serious things that that I guess kind of require that level of diligence. >> You've talked about something that got a lot of attention. You talked about as being the world's gun store, meaning >> That's right. >> We will have the best tech technology available. We're not going to fight your wars, but we may create it so that you will have it to fight your own wars. But do you worry about things that you create being used by people who may not share our values? Yeah. So, I've often said the United States is going to stop being the world police and start being the world's gun store. Meaning, we need to make arms for our allies and our partners around the world. And if you're going to be a gun store, you need to do a good job of it, right? You need to be at a reasonable price. You need to keep things in stock. You can't cut people off arbitrarily. You can't say, \"Sorry, we're not going to have any restock of that for 10 years.\" That's not how you do that effectively. And there's a lot of reasons for that. I think uh one generally I don't think the United States should be sending our men and women off to die for other people's countries unless it's a matter of a last resort but but also I think politically the United States is out of will on this right after a couple decades of misadventures in the Middle East. I don't think we have it in us to send hundreds of thousands of people to go die for someone else's country even if it is for a good cause. I do worry about what you're talking about about weapons being misused or or sent to countries that are going to misuse them. But I don't think I'm the right person to be making the call on when that is or what that is. Remember, I'm a corporate executive. I make weapons and I sell them for money. My opinion inherently should be somewhat disregarded as is tainted. Uh these decisions need to be made by elected politicians, elected officials, people who can be voted into office and then critically can be removed from office by voters. Otherwise, you have no accountability to the electorate. People will often ask me, Palmer, would you make a decision that you should sell to some country without the United States telling you that you should or alternately that you would refuse to sell to some country even if the United States tells you that it's of critical importance to national security or US interests? And the point that I make to them, usually these are more more left-leaning people. And I say, do you really want that kind of system? You want a corportocracy where corporate executives have de facto control of US foreign military affairs. Should should I as a profit motivated entrepreneur be able to decide who gets weapons and who doesn't? I don't think so. I think that the right approach is for people like me to make powerful tools and then leave the decision as to who the right people are to be armed with them up to leaders who again are accountable through an electoral process. By the way, I have no delusions that there will not be mistakes made. I'm sure our elected leaders will make mistakes. I'm sure that every elected leader you can think of has made some mistake, at least, you know, by your definition. Uh, but again, at least we can hold them accountable. We can make sure that things never swing out of control. And if you have a better idea for a better system, I'm all ears, but I haven't heard one yet. >> Pomaki is making a very strong ethical point here. He argues that using AI can and should be used to save innocent lives. We often think of AI in war as scary, but Palmer says we should look at it differently. Think about human pilot flying a jet. They might be tired, stressed, or scared. They might have poor eyesight or be looking at a blurry screen. They can make mistakes and a dumb bomb dropped by a human doesn't know what it hits. It just explodes. If a school bus is near the target, the bomb destroys both. Palmer argues that AI solves this human error. Computers don't get tired. They don't get angry or scared. They have perfect vision in every direction at once. New systems like Andrew's Lattis software acts like a safety check. They can look at a target multiple times a second. If a computer sees a civilian vehicle like a bus, it can lock the weapon so it cannot be fired. This is a huge step forward for human rights in warfare. Just like modern cars have automatic braking to stop you from hitting a pedestrian, modern weapons can have automatic aborts to stop them from hitting a family. By using this tech, we aren't removing human responsibility. We're giving soldiers a tool that helps them follow the rules of war perfectly. If we have the technology to make war less messy and save civilian lives, Palmer argues we have a moral duty to use it. It pushes the military to be more precise and careful than ever. So the technology can make the battlefield safer for civilians. But Palmer Lucky also has a smart plan for how to keep American soldiers safe at home. This is a very practical point for the future. Palmer is saying that the United States should stop fighting everyone else's wars. Instead, the US should empower their friends to protect themselves. For the last 20 years, the US tried to be the world's police. They sent hundreds of thousands of soldiers to difficult places. It cost a lot of money and a lot of lives. Palmaki's gun store idea is a return to a classic American strategy. This sits perfectly with the new reality of 2025. Countries like Ukraine, Poland, and Taiwan want to defend their own borders. They don't necessarily want American soldiers. They want American tools. By mass-producing smart, affordable drones and defense weapon systems, America can give these democracies a shield. This strategy creates stability. If a small democratic country has thousands of smart drones, a larger aggressive neighbor will think twice before attacking them. It creates deterrence. It also helps the American economy. Instead of spending tax dollars on deploying troops abroad, that money could be spent building factories in America. It can create jobs for engineers and manufacturing workers. Palmer points out that elected politicians still have the final say on who buys the weapon. This keeps the system democratic. America is building a network of strong allies and not losing control. With America sharing its best technology, it makes the free world stronger without putting American troops in harm's way. It's a win-win. America's allies get safety, and America gets to stay out of foreign conflicts. If I could recommend one place to start learning AI, it would be this course I put together. It's clear, structured, and designed for beginners who genuinely want to get knowledgeable on AI. You'll get lifetime access to all lessons, including future modules. And just a heads up, the price rises as more modules are added. So, it's currently at the lowest price you'll see. One of our clients started with zero audience. Now, they're doing $100,000 months thanks to YouTube. And they're not alone. We've helped three businesses hit that level just by growing them a YouTube channel. Want to see how this could work for your business? Book a call with me below."
    },
    {
        "video_id": "yM1WcHFM7_4",
        "title": "Important AI Race WARNING",
        "published_at": "2025-12-15T20:03:54.000Z",
        "sort_date": "2025-12-15",
        "url": "https://www.youtube.com/watch?v=yM1WcHFM7_4",
        "views": 5874,
        "duration": "00:10:48",
        "transcript": "2025 has been a gigantic year for companies like Google and OpenAI as they race to get their LLM chat bots out to as many people as possible. Google's recent resurgence put a lot of pressure on ChatGpt to catch up. So the question is who is winning this battle? >> Now we're seeing this race in chat bots. Is there is there a plain language way to look at? Is there some comparison that kind of applies to everyday life that we can look at it? Is it kind of similar to I've heard somebody talk about VHS and beta and the battle isn't over the tech, it's on who can just kind of take the mainstream aspects that people are looking for and deploy it faster. >> So in deploying technology into society or into new markets, there's always going to be two elements of that battle. The first is technological. You cannot be for example a major phone uh provider in the world on on the hardware side if your cameras uh take pictures that still look like the digital cameras from you know maybe 15 years ago. So you have to make sure that the technology itself is up to par and is capable of being able to keep up with others who are developing that technology. But that's only one piece of the battle. The larger battle is thinking about how you capture users attention. So you can build all the great tech that you want, but who will come and actually use that technology? And so as we're trying to figure that out, what we're seeing now is a natural evolution in the AI race to follow that general market concept where they're moving away from fighting over who has the best models, who has the best training techniques, the best inference tech techniques, and we're moving into how do we get users to consistently use our products and technology and profit from that. And so right now the technology gap between Gemini and OpenAI is essentially closed. I mean Gemini 3 is a basically a model a marvel of engineering and you know show is chat GPT5 but again we're moving away from cool technology to how do we get people to use it now in reality Google has more channels to distribute their AI right they can stick it inside of multitude of their products but open AI has something that Google is still fighting for which is habit when you search something you don't search it you Google it well now when you want to think you ask chatgpt and There are 800 million people weekly who use chat GPT and so their moat is human behavior not just code. So, you know, Gemini can be embedded inside of Google's products and be a formidable portion of the market share, but Open AI is betting on the fact that people want more than smart spreadsheets that they want technology that's ingrained into the fabric of society and they're using that to introduce new products. >> X, nobody would know better than you, but I just want to be clear. So, you're saying it's a dead heat when we're looking at OpenAI and Google. You're saying it sounds like you're saying it's even, right? So, with that in mind, as we see the deal between Open Eye and Disney, what does that mean for this race? Because they're going to have the the access to intellectual property that all of us know and all of us love and be able to kind of integrate that into their chatbot and integrate that into their image generators. Is that an edge? Is that a significant edge in your mind? >> That's absolutely a significant edge. I mean the uh Disney franchise is probably one of the largest media franchises in existence uh especially with its penetration from users uh across all age groups and across you know different languages and different regions of the world. And so being able to incorporate that is uh definitely a market driver much like in streaming services right where you may want to watch a particular catalog but in order to do so you'd have to subscribe to one provider to get it. So again, we're seeing natural market trends that we see in other technological areas starting to affect the AI race where again it's no longer about, hey, do we just have the best technology? It's about what are the unique angles we can take to get people to use our technology. So chat GPT brokering that deal um is a step in the right direction for them to continue to be uh the household AI name. >> All right. So far we've been very focused on consumer applications. What about enterprise? After that code red that we heard of open AI, we've been talking a lot about this battle, but it really has been focused on the consumer applications. When we're talking about enterprise, who do you see in the in the the front of that race? And what do you think about OpenAI's efforts in particular? >> So, I believe that they're taking two different approaches. Um, well, let me rephrase this. I believe that there are two different approaches that are being deployed in the market to be able to capture enterprise adoption of AI. The first is to provide infrastructure which is the approach that you see Microsoft and folks like Amazon taking where they're trying to provide the computing power and the actual physical hardware infrastructure and the elements around that for for companies to be able to build their own AI systems or deploy it within their companies. What Open AI is looking at doing instead of following that old way of doing things is they're attempting to build the actual products that businesses would need. Right? And so you see the Instagram CEO coming over. You hear Sam Alman in conversations and in interviews talking about how they're looking to build applications across every vertical. If you go look at their hiring page, they have roles open for people to shape products for specific industries. And so again, if Chad GPT is the household name, they're already ingrained into society. Their battle is about imagining new products. Whereas these larger tech companies are having to go sell innovation. This lady who goes by the name of Xie argues that OpenAI is shifting its strategy because maintaining a permanent technological lead over Google is becoming extremely difficult and costly. Instead, they are trying to differentiate themselves by building a behavioral moat and using Disney characters to lock users in. Xie explicitly calls the Disney deal a significant edge, comparing it to how streaming services use exclusive content to retain subscribers. This represents a major shift in the competitive landscape. For the last 3 years, we were in the model era where value was defined by benchmarks. That era is transitioning because we're hitting a lot of diminishing returns. To the average user, the difference between a model that is only a bit superior to the other is not so critical for daily tasks. So, how do you compete when the underlying technology reaches parody? You compete on emotional infrastructure. The Disney deal is about data gravity. You compete on emotional infrastructure. The Disney deal is about data gravity by integrating 100 years of beloved IP. Open AAI is trying to make Chat GPT the primary destination for creative interaction. This move signals the creation of a totally new type of work. We're moving away from the era where work in entertainment meant a studio spending $200 million to make one movie for everyone. The raw power of these new AR models allows for co-creation where the audience becomes the director. Imagine a freelance graphic designer who can now instantly generate storyboard quality animations using licensed Star Wars assets or a teacher creating a personalized Pixar style lesson plan. This creates a new layer of economic value. We're seeing the birth of the proumer studio where the barrier to entry for professional storytelling drops dramatically. Open AI is betting that the future of work for creatives is collaborating with the world's biggest brands inside their platform. This locks users in not because it is the only place where their work is legally allowed to exist. At least for now, this deal could be the start of a new era of relationship between these big Hollywood studio companies and AI companies. But capturing user attention with Disney is only step one. Step two is the economic challenge. Open AI must transition from selling intelligence to selling solutions to maintain their growth. The clip we just watched highlighted a critical trend. Raw intelligence is becoming a commodity with shrinking margins. So tech companies must diversify by building specific finished products for industries like law, medicine, and design. What we're seeing is often called the electricity versus appliance shift. In the early days, OpenAI was selling the electricity, which was the raw AI model. But as competitors like Google and Anthropic catch up, the price of that raw intelligence drops. To sustain high value, they must start selling appliances, which are finished tools that use the electricity to solve specific problems. And this explains the recruitment of consumer product leaders. They're moving away from building a better brain and towards building a lawyer app that uses the brain to draft contracts. This is also called vertical integration. This pivot highlights that the future of AI is not just generic chat bots, but agents. A chatbot is passive. You ask it a question and it answers. An agent is active. You give it a goal. Plan my travel. Audit this tax return and it executes the work across multiple steps. This creates a new paradigm called service as a software. In the past, you bought software like Microsoft Word to help you do the work. In the future, you will buy a legal agent that does the work for you. This fundamentally changes the nature of human employment from execution to orchestration. The lawyer of the next decade will spend far less time drafting contracts and far more time directing and reviewing AI teams. Open AAI's hiring spree proves that they are racing to build these agents first. They know that only having the best textbox interface is not enough to win this AI war. The real value lies in building specialized autonomous workers that will power the next productivity revolution. If they succeed, they don't just sell you a tool, they sell you a workforce. In the future of work, people who know how to manage AI tools and AI agents will have massive advantages. And we will see the creation of entirely new jobs that don't exist today, similar to what happened when the internet became mainstream. A lot of people want to understand AI properly, but feel overwhelmed by the jargon. I created a structured course that explains the fundamentals in simple language and then moves you on to more advanced topics. When you buy the course, you keep lifetime access to all content and future modules. And just a note, the price will increase as new modules are added. So, this is the cheapest it will ever be. Check out a link for my AI course in the description below. YouTube isn't just entertainment. It's one of the best client acquisition tools because it builds trust at scale. We've helped businesses grow from scratch to a $100,000 month just by launching them a YouTube channel. Book a call with me below and let's see how YouTube could help your business scale."
    }
]
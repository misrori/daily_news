[
    {
        "video_id": "OpVecmqVDh8",
        "title": "Tom Lee: These 2 Sectors Will CRUSH It This Year",
        "published_at": "2026-01-28T12:00:45Z",
        "sort_date": "2026-01-28",
        "url": "https://www.youtube.com/watch?v=OpVecmqVDh8",
        "transcript": "Okay, ladies and gentlemen, I have a big show for you today. Firstly, a discussion on open AI and how much more money the company could potentially make. Then in clip two, we see how AI is moving from something you can chat with to something you can actually build with. And then finally, my favorite clip of the three is Tom Lee and his top picks for 2026. Firstly, on OpenAI, their API business is becoming more valuable than chat GBT itself, believe it or not, and they're now trying to figure out how to capture a share of the economic value their models help create. >> As this AI race now shifts beyond chat bots, our dear DBosa explains in today's tech. Morning D. >> Hey, good morning Carl. So, Alman's not the only one talking about this. Google's Gemini has also been growing this metric and you're going to start hearing a lot more about it. So the metric is API usage. How often the model is being used by enterprise and by developers who are using open AI technology to run their own products. So instead of human typing in a prompt, the software talks directly to the API. One system sends a request. The AI sends back an answer. When a company uses an API, the model that could be chat GPT or Gemini or Claude, it's running inside. It could be inside enterprise software, drug discovery tools, scientific simulations. It's essentially the back end where AI could really drive breakthroughs. It's also one that could be a whole lot more lucrative for OpenAI and transformative for the industry as a whole. Then came the controversial part though, as is often the case with OpenAI CFO Sarah Frier. She suggested that she sees a new opportunity in APIs and that is a value exchange model. In other words, OpenAI could take a cut of its customers AI aided discoveries. Now, some of the immediate feedback pointed to the irony of OpenAI scraping vast amounts of copyrighted data to train its models and then turning around and asking for a share of the value created on top of that intelligence. But another way of looking at it is that this is exactly how Frontier Technology gets funded at scale. That is by tying the economics of the model to the breakthroughs that it helps to unlock. Now, this all raises a bigger question guys about AI economics. Who owns the inputs? who gets paid for the outcomes, not to mention the mechanics of actually executing this kind of a model. Seen together though, and here's maybe the big takeaway at the moment because this is still far away. You had ads earlier this week. Now you have Frier floating another kind of business model. It really shows the pressure that is on OpenAI to find revenue models that are big enough to support its commitments, more than a trillion dollars of commitments that are already locked in. So you see a ramp up and sort of these ideas and how to just create more money and pay for everything it wants to achieve >> on a micro level. Then what happens [clears throat] like for instance I asked my AI a question >> and it used an article that I had written for cnbc.com as the answer. [laughter] So what you know like who should get a piece of that? >> That's exactly >> the irony. Well, that's that's what many are pointing out, right? Is that OpenAI basically scraped the web, all of the articles, everything that was copyrighted, vast amounts of this kind of copyrighted data to build the model, and now it wants to charge people using its model. So, Contessa, you hit the irony exactly. That's why people are kind of upset about the entire idea. Um, but I guess the thinking is like what's done is done. Where do we go next? If >> open AI models can enable these huge scientific discoveries, that's great and maybe they deserve more of a cut, but you know, you're not you're not wrong. >> So, I think this point was really important about API usage being a key metric. When most people think about open AI, they think about chat GPT, which is the standard typing in prompts and getting answers on the UI we are all familiar with. But the real money or potentially the real money and the real transformational stuff is what's happening in the back end where other software is talking directly to OpenAI's models. For example, drug discovery tools, scientific simulators, and enterprise applications. All of this is running through the API. And the economics are completely different. Instead of one person asking one question, you've got automated systems making thousands of requests per second. And that's where the revenue really scales. And also this idea was dropped of a value exchange model. Essentially, Open AI wanting a cut of whatever breakthroughs that AI helps create. Think about what that means. If Eli Liy uses Open AI's API to help discover a new drug, Open AAI might want a percentage of the upside. It's basically the pharmaceutical royalty model applied to AI. You provided the brain that made the discovery possible. So you use a slice of that outcome that could potentially be a way more lucrative business than just charging per API call if OpenAI can pull it off, which we'll see. There is a certain level of irony here though, and it's a pretty big one. Open AAI built these models by scraping the entire internet, articles, research papers, books, basically everything that was ever written online. They didn't ask for permission. They didn't pay for almost all of it. and are they want to charge other people for the value created on top of that intelligence? The journalist literally asks about her own CNBC article being used as an answer. Where's her cup? It's a fair question that doesn't have a great answer to it for Open AI, but still there's another way of looking at this. Building Frontier AI is insanely expensive. Open AAI has over a trillion dollars in commitment already locked in. They're burning through cash, buying data centers, hiring talent, buying compute. The subscription model for chatb probably isn't enough to sustain that. You're seeing the idea of ads floated one day, value exchange models the next. That tells you how much pressure openai is under to find revenue streams big enough to match their ambition. The desperate creativity around monetization is kind of the point here. If you want to go from AI is confusing, the desperate creativity around monetization is kind of the point here. Quick plug. If you're enjoying all this AI talk and you want to go from AI is confusing to feeling confident using and understand it, I built a course that is built for you. It breaks down the essentials and covers things like compute, hardware, and how AI actually works in the real world. If you join today, you get lifetime access, and because the course expands over time, the price will also go up over time. So, now is the best time to join. Back to the video. So, OpenAI is scrambling to find business models that work. But meanwhile, Anthropic is taking a completely different approach. In this next clip, we'll see something that I think actually signals where AI is headed. Anthropics Claude is turning AI into a tool that anyone can build with, and the results are kind of mind-blowing. >> So, OpenAI is playing catch-up here because it's been win after win for Anthropics Cloud Code over the last few weeks as I've been talking all about it. With Co-work, Cloud made it possible to build fully functional apps with just a few prompts. Now with its Excel integration, anyone can do the work of a financial analyst with just a few prompts. Now we all as CNBC anchors and reporters, we pour through sellside notes on the daily. But with Claude and Excel, I could get at exactly the insight that I was looking for. Key assumptions, sensitivities that matter, bull and bear cases, all without digging through 20 or 100 pages of someone else's framework. Now for Alphabet, the question heading into earnings is the AI tax. AI search queries, they cost more to serve than traditional ones. And with AI mode, Google is serving them to a billion plus users. The big question is whether AI search expands or quietly erodess the business. So I asked Claude to build a scenarios tab that you're looking at it right now. It shows the bull bear base cases that I can toggle between by just writing bull or bear in that cell. In less than 10 minutes, I had this this analysis. You can see exactly where AI costs start to pressure margins. How much revenue has to grow to offset it all without touching a single cell to build this. Now, with another prompt, Claude gave me this takeaway showing that the best case versus worst case scenario for Alphabet in this scenario is a nearly 11 billion difference on gross income. Now, guys, this does beg the question, why hasn't Microsoft or Google built this into Excel or Sheets itself? Now legacy tech one reason maybe it's because they're layering AI on top of old foundations the sort of innovator's dilemma whereas anthropic is AI native it's actually rebuilding how these tools get used so it's not just formatting it's not just looking and calculating but it's reasoning with the numbers in the spreadsheet guys I know that this sounds wonky but it does point to a real shift AI is moving from something that most people chat with to something that you can actually build with I mean even without coding or Excel skills I'm creating stuff that used to require a whole team or very specific training. So, we'll see what OpenAI unveils today. But the race, it is no longer about who has the best chatbot. And that is going to lead to a very, very interesting year ahead in the industry and for us as users. >> AI is evolving from something you ask questions to to something that builds for you and whoever wins that race captures a fundamentally different market. So, we've just been walked through this demo where she built a full financial analyst to tour in Excel. bull and best scenarios for Google, otherwise known as Alphabet. Sensitivity analysis, the works, and she did it in under 10 minutes with no coding. I'm personally working with tools that are giving me mind-blowing results with clawed code and replet. I'm making applications just by describing what I want. A year ago, that would have required a development team and a few weeks or maybe even months of work. Now, someone with no expertise like me can do it over lunch. And this is the key insight. The competitive battlefield for AI has shifted. Open AAI, Google, and Anthropic all have roughly comparable chat bots at this point. If you ask them the same question, you'll get answers that are maybe one percentage point different in quality. So, the chatbot race is basically a tie. The new race is about who can turn AI into the best building tool. Something that doesn't just answer your questions, but actually creates things on your behalf. And this is a very fair question. Why hasn't Microsoft or Google built this into Excel or sheets themselves in an effective manner yet? The short answer is the innovator's dilemma. These companies have decades of legacy architecture they're trying to layer AI on top of whereas Anthropic has started from fresh. They're AI native. So they're not constrained by what spreadsheets or word processes were supposed to be used for. They can rethink the whole workflow from scratch. And that's a structural advantage that's hard to replicate. And this matters for what we're all going to be doing with AI over the next few years. The chatbot era was asking questions and getting answers. The next era is about building apps, analysis, and entire workflows. The companies that figure out how to make AI the best collaborator, not just the best answer are going to capture the real valuable piece of this market. And right now, Anthropic seems to be ahead on that particular race. And now let's take a look at this clip with Tom Lee where he picks his top sectors for 2026. >> It's been a turbulent week. >> Is it portend something that's going to come forward here for us? >> Uh well part of it is of course as you know we're in earnings season and markets tend to be volatile around earnings. I I'd say that some of the high-profile declines like Intel look bad over a one-day period, but Intel was $17 a year ago. So to me, it doesn't surprise me that you could see some of those uh stocks have done really well get punished a little bit on earnings. >> I don't I mean this is a hard one to say it's representative of of anything. I mean, you know, the company's obviously been challenged. They have the government backs stop in there and the stock was up a ton >> going into the into the print. As we turn, speaking of the print, the prints that matter next week, the mega caps, which you still love >> but not quite as much. Uh, I mean, we we we still like the Mag 7 and the Mega Caps because they're great earning stories and they have a lot of visibility, but as you know, our top picks this year in terms of sector is energy and basic materials, but as far as earning stories go, yeah, I think next week's critical cuz you got most of the mag 7 reporting. >> Tom, you're crushing that so far with that call. Energy and materials are the two top sectors. Why were you leaning that direction as the year began? uh you know we were betting a bit of mean reversion taking place in 2026. Uh one of the things we identified in our 2026 outlook in early December was that energy and materials underperformed over the last 5 years at a level that if in the last 50 years have marked turning points higher. So we were betting that so much of the bad news was baked in that they could have okay fundamental years but the stocks could do really well. I feel like you were on the right path as it pertains to small caps and the Russell just a little early. I mean, remember, let's remind people last year you told me up here that we're going to have a 50% gain in in the Russell. Um, now obviously we didn't have that, but >> the the Russell is almost outperforming everything else over the past year and in one month it's up 5%. Yeah. >> That going to continue? >> Yeah. Uh, one of the things we we talked about a lot about last year was that when small caps turn, it tends to be a multi-year, in fact, it could be up to a 12-ear period. So, the last turning point for small caps and on a relative price to sales last year or price to book, they were at the exact same point they were in 2001. That was a launch point for 12 years of relative outperformance. So, I think small caps benefit from a Fed turning dovish, possible M&A wave coming, an ISM turning back above 50, and then catching up to where EM cuz EM did really well last year, but and small caps usually track that. It didn't. YouTube isn't just entertainment. It's one of the best client acquisition tools because it builds trust at scale. We've helped businesses grow from scratch to a $100,000 month just by launching them a YouTube channel. Book a call with me below and let's see how YouTube could help your business scale."
    }
]